<h3>Statistical Modeling</h3>

<p>Predictions were made from the classified training polygons using the Random Forests (RF) algorithm implemented with the randomForest package in the R statistical environment [43,44]. Random Forests is a machine learning algorithm derived from Classification and Regression Trees (CART). CART is a recursive partitioning algorithm that searches a parameter space for a variable value that splits a data set into two leaves with the minimum possible classification error. It continues to split the leaves of the tree until some stopping rule such as “terminal leaf node variance dropping below some maximum value” is reached. Random Forests performs multiple iterations of a CART-style algorithm. For each tree it subsamples both the data and the predictor variable set. This analysis used a binary change/no-change response with 2500 trees sampling 7 variables for each split. However it has been shown that the quantity of variables at each split has little effect on the final outcome once the error rate has stabilized. The model splits the full dataset into changed and non-changed strata from which 2500 random polygons were sampled from each to create the Round 2 model response data. The relative proportion of change polygons, including false change predictions was generally low compared to the non-change portion. These strata were created to ensure an adequate sample of change polygons. These were classified correctly as change/no-change and reviewed for the final model using the AAViewer developed for this project. The 5,000 total samples were reviewed and then used to create the final Round 2 model. The final prediction for any single polygon was the result of applying the 2500 derived trees to that polygon’s data values. The probability of change was the proportion of model runs that predicted the polygon of interest to have changed. From a classification standpoint, that means a change polygon is any polygon with greater than 1250 trees resulting in a classification of changed or more simply a fraction of change predictions ≥ 0.5. Predictions from the final model were used to assess the confusion matrix for the modeling procedure. The final summary output for a RF model run displays the confusion matrix for the last generated tree. This is an assessment of the classification accuracy of the single final tree. To assess the model’s overall ability to discriminate amongst the input data, the model data was run through the full prediction procedure to assess the most probable class for each training polygon after being evaluated by the full “Forest” of prediction trees. Interpreting RF results can be difficult if the analytical goal is to come up with a mechanistic model for change. The probability of change is a summary statistic calculated over the “Forest” of trees. Each individual tree has a specific deterministic decision tree, but the whole model run integrates over many stochastic trials. Relative importance is attributed to different variables depending on their cumulative contribution over the individual model runs. </p>